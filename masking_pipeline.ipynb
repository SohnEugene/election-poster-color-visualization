{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzbcx5goGCv4",
        "outputId": "8c0a2966-a4af-42fe-ceb1-1f8d7c5d5e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "from os.path import join\n",
        "import tarfile\n",
        "import urllib   # 웹에서 데이터를 다운로드 받을 때 사용\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import copy\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It1vHBEHX-SG"
      },
      "source": [
        "## 텍스트 영역 인식\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-o_gX4v2VhP"
      },
      "outputs": [],
      "source": [
        "# 이미지 리사이즈\n",
        "\n",
        "def resize_image(img, new_width=1000):\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image\")\n",
        "        return\n",
        "\n",
        "    height, width, channels = img.shape\n",
        "    new_height = int((new_width / width) * height)\n",
        "\n",
        "    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
        "    return resized_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-DbdwkBXKXY"
      },
      "outputs": [],
      "source": [
        "# 얼굴 영역 인식\n",
        "\n",
        "cascade_filename = \"\" #가중치 파일 경로\n",
        "cascade = cv2.CascadeClassifier(cascade_filename) #모델 불러오기\n",
        "\n",
        "SCALE_FACTOR = 1.05\n",
        "MIN_NEIGHBORS = 3\n",
        "FACE_DENOMINATOR = 8\n",
        "\n",
        "def imgDetector(img,cascade, file_name):\n",
        "    # 그레이 스케일 변환\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    min_face_size = img.shape[1]//FACE_DENOMINATOR\n",
        "    results = cascade.detectMultiScale(gray, scaleFactor= SCALE_FACTOR, minNeighbors=MIN_NEIGHBORS, minSize=(min_face_size, min_face_size))\n",
        "    if type(results) == tuple:\n",
        "        print(\"ERROR: no face detect for \" + file_name)\n",
        "    return results[0]\n",
        "\n",
        "def boxFace(img, file_name) :\n",
        "    points = imgDetector(img, cascade, file_name)\n",
        "    x, y, w, h = points\n",
        "    w_offset = w//6\n",
        "    h_offset = h//6\n",
        "    newPoints = [x+w_offset, y-h_offset, w-(2*w_offset), h+(2*h_offset)]\n",
        "    return newPoints\n",
        "\n",
        "def drawBox(img, boxes, r, g, b) :\n",
        "    clone = img.copy()\n",
        "    for box in boxes :\n",
        "        x, y, w, h = box\n",
        "        cv2.rectangle(clone, (x,y), (x+w, y+h), (b,g,r), thickness=5)\n",
        "    cv2_imshow(clone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHqOXJupj9AL"
      },
      "outputs": [],
      "source": [
        "# 텍스트 영역 인식\n",
        "\n",
        "def kernelSize(img, denominator) :\n",
        "    w = img.shape[0]\n",
        "    kSize = w//denominator\n",
        "    if (kSize % 2 == 0):\n",
        "        kSize += 1\n",
        "    return kSize\n",
        "\n",
        "\n",
        "def extractText(img, denominator) :\n",
        "    start = time.time()\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    kSize = kernelSize(img, denominator)\n",
        "\n",
        "    gray = cv2.GaussianBlur(gray, (kSize, kSize), 0)\n",
        "\n",
        "    mser = cv2.MSER_create()\n",
        "    regions,_ = mser.detectRegions(gray)\n",
        "\n",
        "    hulls = [cv2.convexHull(p.reshape(-1, 1, 2)) for p in regions]\n",
        "\n",
        "    tmp = list()\n",
        "    count = 0\n",
        "    for j, cnt in enumerate(hulls):\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        tmp.append([x, y, w, h])\n",
        "        count+=1\n",
        "    return tmp\n",
        "\n",
        "def drawTextBox(img, boxes) :\n",
        "    clone = img.copy()\n",
        "    for box in boxes :\n",
        "        cv2.rectangle(clone, (box[0], box[1]), (box[0] + box[2], box[1] + box[3]), (0, 255,0), 2)\n",
        "    cv2_imshow(clone)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 박스 그리기 + 영역 계산\n",
        "\n",
        "def detectIntersection(textBoxes, faceBox) :\n",
        "    Fx, Fy, Fw, Fh = faceBox\n",
        "    result = list()\n",
        "    for box in textBoxes :\n",
        "        x, y, w, h = box\n",
        "        p1 = [x, y]\n",
        "        p2 = [x+w, y]\n",
        "        p3 = [x, y+h]\n",
        "        p4 = [x+w, y+h]\n",
        "        tmp = [p1, p2, p3, p4]\n",
        "        for point in tmp :\n",
        "            if (point[0] >= Fx and point[0] <= Fx+Fw and point[1] >= Fy and point[1] <= Fy+Fh) :\n",
        "                break\n",
        "        else :\n",
        "            result.append(box)\n",
        "    return result\n",
        "\n",
        "def drawBox(img, boxes) :\n",
        "    clone = img.copy()\n",
        "    for box in boxes :\n",
        "        x, y, w, h = box\n",
        "        cv2.rectangle(clone, (x,y), (x+w, y+h), (0,255,0), thickness=1)\n",
        "    cv2_imshow(clone)\n",
        "\n",
        "def green_rectangles(img, boxes):\n",
        "    clone = img.copy()\n",
        "    for rect in boxes:\n",
        "        x, y, w, h = rect\n",
        "        clone[y:y+h, x:x+w] = (0, 255, 0)\n",
        "\n",
        "    return clone"
      ],
      "metadata": {
        "id": "8Lho6gX94FmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 얼굴 인식 함수"
      ],
      "metadata": {
        "id": "bjvZYGU37Zhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepLabModel(object):\n",
        "    INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
        "    OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
        "    INPUT_SIZE = 513\n",
        "    FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
        "\n",
        "    def __init__(self, tarball_path):\n",
        "        self.graph = tf.Graph()\n",
        "        graph_def = None\n",
        "        tar_file = tarfile.open(tarball_path)\n",
        "        for tar_info in tar_file.getmembers():\n",
        "            if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
        "                file_handle = tar_file.extractfile(tar_info)\n",
        "                graph_def = tf.compat.v1.GraphDef.FromString(file_handle.read())\n",
        "                break\n",
        "        tar_file.close()\n",
        "\n",
        "        with self.graph.as_default():\n",
        "    \t    tf.compat.v1.import_graph_def(graph_def, name='')\n",
        "\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "\n",
        "    def preprocess(self, img_orig):\n",
        "        height, width = img_orig.shape[:2]\n",
        "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
        "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
        "        resized_image = cv2.resize(img_orig, target_size)\n",
        "        resized_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
        "        img_input = resized_rgb\n",
        "        return img_input\n",
        "\n",
        "    def run(self, image):\n",
        "        img_input = self.preprocess(image)\n",
        "\n",
        "        batch_seg_map = self.sess.run(\n",
        "            self.OUTPUT_TENSOR_NAME,\n",
        "            feed_dict={self.INPUT_TENSOR_NAME: [img_input]})\n",
        "\n",
        "        seg_map = batch_seg_map[0]\n",
        "        return cv2.cvtColor(img_input, cv2.COLOR_RGB2BGR), seg_map"
      ],
      "metadata": {
        "id": "QdC71Li57Y6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = DeepLabModel(\"\") # Deeplab 모델 경로\n",
        "\n",
        "LABEL_NAMES = [\n",
        "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
        "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
        "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'\n",
        "]\n",
        "len(LABEL_NAMES)"
      ],
      "metadata": {
        "id": "2ZDxpFK-8Jkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 추출된 영역 다듬기\n",
        "\n",
        "def filter_small_mask_areas(mask, min_area_threshold):\n",
        "    # 마스크 영역의 바이너리 이미지에서 연결된 컴포넌트를 찾음\n",
        "    # 바이너리 마스크에서 연결된 컴포넌트 찾기\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # 마스크에서 작은 영역을 제거하기 위한 마스크 생성\n",
        "    filtered_mask = np.zeros_like(mask)\n",
        "\n",
        "    # 마스크에서 컨투어 영역의 넓이를 계산하고, 일정 크기 이상인 경우만 유지\n",
        "\n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area >= min_area_threshold:\n",
        "            contour_mask = np.zeros_like(mask)\n",
        "            cv2.drawContours(contour_mask, [contour], 0, 255, -1)\n",
        "\n",
        "            contour_pixels = mask[contour_mask == 255]\n",
        "            average_color = contour_pixels[0]\n",
        "            if average_color != 0:\n",
        "                cv2.drawContours(filtered_mask, [contour], 0, 255, -1)\n",
        "\n",
        "    return filtered_mask\n",
        "\n",
        "\n",
        "\n",
        "def adjust_mask(img_mask_up, boxed):\n",
        "    # 원본 이미지에서 초록색 픽셀 위치 찾기\n",
        "    black_indices = np.where(np.all(boxed == [0, 255, 0], axis=-1))\n",
        "\n",
        "    for i in range(len(black_indices[0])):\n",
        "        y, x = black_indices[0][i], black_indices[1][i]\n",
        "        img_mask_up[y, x] = 0\n",
        "\n",
        "    return img_mask_up\n",
        "\n",
        "def adjust_mask2(img_mask_up, bar) :\n",
        "    adjusted_mask = img_mask_up.copy()\n",
        "\n",
        "    height, width = adjusted_mask.shape\n",
        "    for y in range(bar, height):\n",
        "        for x in range(width):\n",
        "            if adjusted_mask[y, x] == 255:\n",
        "                adjusted_mask[y, x] = 0\n",
        "\n",
        "    return adjusted_mask\n",
        "\n",
        "\n",
        "def green_mask(boxed, original) :\n",
        "    img_resized, seg_map = MODEL.run(original)\n",
        "    seg_map = np.where(seg_map == 15, 15, 0) # 예측 중 사람만 추출\n",
        "    img_mask = seg_map * (255/seg_map.max()) # 255 normalization\n",
        "    img_mask = img_mask.astype(np.uint8)\n",
        "\n",
        "    img_mask_up = cv2.resize(img_mask, original.shape[:2][::-1], interpolation=cv2.INTER_LINEAR)\n",
        "    _, img_mask_up = cv2.threshold(img_mask_up, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "\n",
        "    img_mask_up = adjust_mask(img_mask_up, boxed)\n",
        "    img_mask_up = adjust_mask2(img_mask_up, 1000)\n",
        "    img_mask_up = filter_small_mask_areas(img_mask_up, 10000)\n",
        "\n",
        "\n",
        "    mask_color = (0, 255, 0)  # 변경할 색상 설정\n",
        "    masked_img = np.zeros_like(original)  # 원본 이미지와 동일한 크기의 검은색 이미지 생성\n",
        "    masked_img[img_mask_up == 255] = mask_color\n",
        "    masked_img[img_mask_up == 0] = original[img_mask_up == 0]\n",
        "\n",
        "    return masked_img"
      ],
      "metadata": {
        "id": "xGxxIIGd8L9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA93ahUij36j"
      },
      "source": [
        "## 실행 코드"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = \"\"\n",
        "output_folder = \"\"\n",
        "\n",
        "dir_list = [] # 마스킹할 이미지가 담긴 폴더 리스트\n",
        "count = 0\n",
        "\n",
        "for path in dir_list :\n",
        "    new_path = output_folder + path\n",
        "    os.makedirs(new_path, exist_ok=True)\n",
        "\n",
        "    print(f\"Directory created: {new_path}\")\n",
        "\n",
        "for name in dir_list :\n",
        "    print()\n",
        "    print()\n",
        "    print(f\"new folder: {name}\")\n",
        "    input_dir = input_folder + name\n",
        "    output_dir = output_folder + name\n",
        "\n",
        "    file_list = os.listdir(input_dir)\n",
        "\n",
        "    images = []\n",
        "    image_num = 0\n",
        "\n",
        "    for file_name in file_list:\n",
        "        img_path = os.path.join(input_dir, file_name)\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is not None:\n",
        "            images.append([file_name, resize_image(image)])\n",
        "            count += 1\n",
        "            if (count % 20 == 0) :\n",
        "                print(count)\n",
        "\n",
        "    print(\"불러온 이미지 개수:\", len(images))\n",
        "\n",
        "    resized_images = images\n",
        "\n",
        "    for i in range(len(resized_images)):\n",
        "\n",
        "        if (i%10 == 0) :\n",
        "            print(f\"currenty at {i}\")\n",
        "\n",
        "        try :\n",
        "\n",
        "            filename = resized_images[i][0]\n",
        "            image = resized_images[i][1]\n",
        "\n",
        "            faceBox = boxFace(image, filename)\n",
        "            textBoxes = extractText(image, 150)\n",
        "            newTextBoxes = detectIntersection(textBoxes, faceBox)\n",
        "            boxed = green_rectangles(image, newTextBoxes)\n",
        "\n",
        "            result = green_mask(boxed, image)\n",
        "\n",
        "            file_path = os.path.join(output_dir, filename)\n",
        "            cv2.imwrite(file_path, result)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred at index {i}: {e}\")"
      ],
      "metadata": {
        "id": "TvMYR8I0e7rZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bjvZYGU37Zhn"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
